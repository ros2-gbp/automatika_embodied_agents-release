# Examples ‚ú®

Welcome to the **_EmbodiedAgents_ Examples** section!

Here you‚Äôll find a curated set of short, focused tutorials that demonstrate how to use **EmbodiedAgents** to build real-world robotic capabilities through its modular architecture. These examples illustrate how perception, language, planning, memory, and control can be integrated to build powerful embodied systems.

Each tutorial walks through one or more [components](../basics/components.md) (e.g., LLM, SpeechToText etc.), and is designed to be run end-to-end. We recommend going through them in order, especially if you're new to the framework.

---

## üîç What You‚Äôll Learn

- How to load and configure components
- How to connect components in an arbitrary graph
- How to build complex physical agents that reason and act in simulated or real environments

---

```{toctree}
:maxdepth: 1

conversational
prompt_engineering
semantic_map
goto
tool_calling
semantic_router
complete
multiprocessing
```

---

Each example includes:

- **Minimal working code**
- **Explanation of design choices**
- **Conceptual takeaways**
- **Ways to customize or extend**

Stay curious, and feel free to adapt these examples to your robot, simulation, or use case!

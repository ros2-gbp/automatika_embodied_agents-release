# EmbodiedAgents

**Production-grade framework to deploy Physical AI on real world robots.**

<p style="font-size: 1.1em; opacity: 0.8;">
  Create interactive, <b>physical agents</b> that do not just chat, but <b>understand</b>, <b>move</b>, <b>manipulate</b>, and <b>adapt</b> to their environment.
</p>

[Get Started](quickstart) • [View on GitHub](https://github.com/automatika-robotics/embodied-agents)

<span class="sd-text-primary" style="font-weight: bold; font-size: 1.1em;">{material-regular}`precision_manufacturing;1.5em;sd-text-primary` Production Ready - </span> Designed for autonomous systems in dynamic environments. Provides an orchestration layer for **Adaptive Intelligence**, making Physical AI simple to deploy.

<span class="sd-text-primary" style="font-weight: bold; font-size: 1.1em;">{material-regular}`autorenew;1.5em;sd-text-primary` Self-Referential - </span> Create agents that can start, stop, or reconfigure their components based on internal or external events. Trivially switch from cloud to local ML or switch planners based on location or vision input. Make agents self-referential [Gödel machines](https://en.wikipedia.org/wiki/G%C3%B6del_machine).

<span class="sd-text-primary" style="font-weight: bold; font-size: 1.1em;">{material-regular}`memory;1.5em;sd-text-primary` Spatio-Temporal Memory - </span> Provides embodiment primitives like a heirarchical spatio-temporal memory and semantic routing to build arbitrarily complex graphs for agentic information flow. No need to utilize bloated "GenAI" frameworks on your robot.

<span class="sd-text-primary" style="font-weight: bold; font-size: 1.1em;">{material-regular}`code;1.5em;sd-text-primary` Pure Python, Native ROS2 - </span> Define complex asynchronous graphs in standard Python without touching XML launch files. Yet, underneath, it is pure ROS2; compatible with the entire ecosystem of hardware drivers, simulation tools, and visualization suites.


## Get Started

::::{grid} 1 2 2 3
:gutter: 2

:::{grid-item-card} {material-regular}`download;1.2em;sd-text-primary` Installation
:link: installation
:link-type: doc

Setup EmbodiedAgents on your system
:::

:::{grid-item-card} {material-regular}`rocket_launch;1.2em;sd-text-primary` Quickstart
:link: quickstart
:link-type: doc

Launch your first embodied agent in minutes
:::

:::{grid-item-card} {material-regular}`menu_book;1.2em;sd-text-primary` Basic Concepts
:link: basics/components
:link-type: doc

Learn the core building blocks of the framework
:::

:::{grid-item-card} {material-regular}`auto_awesome;1.2em;sd-text-primary` Examples
:link: examples/foundation/index
:link-type: doc

Explore foundation recipes and get introduced to system components
:::

:::{grid-item-card} {material-regular}`smart_toy;1.2em;sd-text-primary` AI-Assisted Coding
:link: llms.txt
:link-type: url

Get the `llms.txt` for your coding-agent and let it write the recipes
:::
::::

## Contributions

_EmbodiedAgents_ has been developed in collaboration between [Automatika Robotics](https://automatikarobotics.com/) and [Inria](https://inria.fr/). Contributions from the community are most welcome.

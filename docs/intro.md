<div>
  <img src="_static/EMBODIED_AGENTS_LIGHT.png" class="only-light" />
  <img src="_static/EMBODIED_AGENTS_DARK.png" class="only-dark" />
</div>
<br/>

# EmbodiedAgents ü§ñ

EmbodiedAgents is a fully-loaded framework, written in pure ROS2, for creating interactive physical agents that can understand, remember, and act upon contextual information from their environment.

- **Production Ready Physical Agents:** Designed to be used with autonomous robot systems that operate in real world dynamic environments. EmbodiedAgents makes it simple to create systems that make use of Physical AI.
- **Intuitive API**: Simple pythonic API to utilize local or cloud based ML models (specifically **Multimodal LLMs** and other **transformer based architectures**) on robots.
- **Semantic Memory**: Integrates vector databases, semantic routing and other supporting components to quickly build arbitrarily complex graphs for agentic information flow. No need to utilize bloated "GenAI" frameworks on your robot.
- **Made in ROS2**: Utilizes [ROS2](https://docs.ros.org/en/kilted/index.html) as the underlying distributed communications backbone. Theoretically, all devices that provide a ROS2 package can be utilized to send data to ML models, with callbacks implemented for most commonly used data types and infinite extensibility.

Checkout [Installation Instructions](installation.md) üõ†Ô∏è

Get started with the [Quickstart Guide](quickstart.md) üöÄ

Get familiar with [Basic Concepts](basics.md) üìö

Dive right in with [Examples](examples/index.md) ‚ú®

## Contributions

Embodied Agents has been developed in collaboration between [Automatika Robotics](https://automatikarobotics.com/) and [Inria](https://inria.fr/). Contributions from the community are most welcome.
